{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe1a65c",
   "metadata": {},
   "source": [
    "# INDICE INVERTIDO / INDICE INVERSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9299aa81",
   "metadata": {},
   "source": [
    "## OBTENCI√ìN DE TODOS LOS TERMINOS\n",
    "Leemos el archivo llamado DocumentoPreprocesado.txt para poder obtener todos los terminos del documento (sin repetirlos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e3c2df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminos=[]\n",
    "tabla=[]\n",
    "documentos=[]\n",
    "with open(\"DocumentoPreprocesado.txt\",encoding=\"utf8\") as file1:#LEECTURA DEL DOCUMENTOS PARA LA OBTENCION DE TERMINOS  \n",
    "    for linea in file1:\n",
    "        documentos.append(linea)\n",
    "        words = linea.split() \n",
    "        for word in words:\n",
    "            terminos.append(word)                               #AGREGAMOS LA PALABRA A LA LISTA TERMINOS \n",
    "    terminos = list(set(terminos))                              #PARA QUITAR LOS TERMINOS REPETIDOS DE LA LISTA\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25015cb1",
   "metadata": {},
   "source": [
    "#### IMPRIMIMOS LOS TERMINOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183d2c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sergej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smirkingface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seriedemods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>defenderte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>dora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>locomotora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>harvest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1224 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0           sergej\n",
       "1     smirkingface\n",
       "2             cafe\n",
       "3      seriedemods\n",
       "4            parte\n",
       "...            ...\n",
       "1219    defenderte\n",
       "1220          dora\n",
       "1221             p\n",
       "1222    locomotora\n",
       "1223       harvest\n",
       "\n",
       "[1224 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(terminos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ea5927",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DocumentoPreprocesado.txt\",encoding=\"utf8\") as file1:  \n",
    "    for linea in file1:\n",
    "        words = linea.split()                      #WORDS SON LAS PALABRAS DE NUESTRO DOCUMENTO/LINEA (LISTA)\n",
    "        numDePalabras = dict.fromkeys(terminos, 0) #ASIGNAMOS 0 A LOS TERMINOS DE NUESTRO DICCIONARIO (NUMDEPALABRAS)\n",
    "        for word in words:                         #POR CADA PALABRA DE NUESTRO DOCUMENTO\n",
    "            numDePalabras[word] += 1               #CONTAMOS CUANTAS VECES SE ENCUENTRA ESA PALABRA EN EL DOCUMENTO Y ACTUALIZAMOS EL DICCIONARIO\n",
    "        tabla.append(numDePalabras)                #NUESTRA TABLA ES UNA LISTA DE DICCIONARIOS (1 DICCIONARIO POR CADA DOCUMENTO)\n",
    "        documentos.append(words)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e943e",
   "metadata": {},
   "source": [
    "## INDICE INVERSO CON OCURRENCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e991d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_invertido = {} \n",
    "i=0\n",
    "for documento in documentos:                   #PARA CADA UNO DE LOS DOCUMENTOS\n",
    "    for termino in terminos:                   #PARA CADA UNO DE LOS TERMINOS\n",
    "        ubi_fre= []                            #LISTA QUE CONTIENE LA UBICACION DEL TERMINO (EL DOCUMENTO) Y SU FRECUENCIA\n",
    "        if termino in documento:               #SI EL TERMINO SE ENCONTRO EN EL DOCUMENTO\n",
    "            if termino not in indice_invertido:#SI AUN NO ESTA EL TERMINO EN LA LISTA INVERTIDA\n",
    "                indice_invertido[termino] = [] #SE AGREGA AL DICCIONARIO EL TERMINO Y UNA LISTA VACIA DONDE SE ALMACENAR√Å\n",
    "                                               #UBI_FRE\n",
    "            if termino in indice_invertido:    #SI EL TERMINO EST√Å EN EL INDICE INVERTIDO\n",
    "                frecuencia=tabla[i][termino]\n",
    "                ubi_fre.append(i+1)            #SE AGREGA A UBI_FRE EL NUMERO DEL DOCUMENTO \n",
    "                ubi_fre.append(frecuencia)#SE AGREGA A UBI_FRE LA FRECUENCIA DEL TERMINO EN ESE DOCUMENTO\n",
    "                if frecuencia != 0:\n",
    "                    indice_invertido[termino].append(ubi_fre)#SE AGREGA AL INDICE INVERTIDO UBI_FRE\n",
    "    i=i+1\n",
    "    if i == len(tabla):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa72b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocabulario</th>\n",
       "      <th>Ocurrencias √≠ndice invertido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v</td>\n",
       "      <td>[[286, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tweeted</td>\n",
       "      <td>[[1, 1], [2, 1], [3, 1], [4, 1], [5, 1], [6, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l</td>\n",
       "      <td>[[80, 1], [242, 1], [247, 1], [333, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im</td>\n",
       "      <td>[[1, 1], [225, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dia</td>\n",
       "      <td>[[10, 1], [63, 1], [85, 1], [157, 1], [195, 2]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>demasiado</td>\n",
       "      <td>[[349, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>suspender</td>\n",
       "      <td>[[350, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>presente</td>\n",
       "      <td>[[350, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>momentaneamente</td>\n",
       "      <td>[[350, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>lluvia</td>\n",
       "      <td>[[350, 1]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1224 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Vocabulario                        Ocurrencias √≠ndice invertido\n",
       "0                   v                                         [[286, 1]]\n",
       "1             tweeted  [[1, 1], [2, 1], [3, 1], [4, 1], [5, 1], [6, 1...\n",
       "2                   l            [[80, 1], [242, 1], [247, 1], [333, 1]]\n",
       "3                  im                                 [[1, 1], [225, 1]]\n",
       "4                 dia  [[10, 1], [63, 1], [85, 1], [157, 1], [195, 2]...\n",
       "...               ...                                                ...\n",
       "1219        demasiado                                         [[349, 1]]\n",
       "1220        suspender                                         [[350, 1]]\n",
       "1221         presente                                         [[350, 1]]\n",
       "1222  momentaneamente                                         [[350, 1]]\n",
       "1223           lluvia                                         [[350, 1]]\n",
       "\n",
       "[1224 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd   \n",
    "df = pd.DataFrame([[key, indice_invertido[key]] for key in indice_invertido.keys()], columns=['Vocabulario ', 'Ocurrencias √≠ndice invertido'])#SE IMPRIMRE EL DATAFRAME CREADO CON EL NUEVO DICCIONARIO CREADO POR LA FUNCION IDF\n",
    "df     #IMPRIMIMOS EL DATA FRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474875c4",
   "metadata": {},
   "source": [
    "### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c42f7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def TF(documento):                              #RECIBIMOS UN DICCIONARIO QUE ES NUESTRO DOCUMENTO CON LA FRECUENCIA\n",
    "    tfDict = {}                                 #CREAMOS UN DICCIONARIO PARA TF\n",
    "    for word, fij in documento.items():         #SE EMPIEZA CON LA LECTURA DE CADA PALABRA DEL DOCUMENTO Y OBTENEMOS SU FRECUENCIA\n",
    "        if fij != 0:                           \n",
    "            tfDict[word] = 1 + math.log2(fij)   #SI ùëìùëñ,ùëó > 0 SE REALIZA LA OPERACI√ìN\n",
    "        else:\n",
    "            tfDict[word] = 0                    #EN OTRO CASO SE ASIGNA 0\n",
    "    return tfDict \n",
    "\n",
    "tf=[]                        #LISTA DE DICCIONARIOS DE TF\n",
    "for documento in tabla:      #SE RECORREN LOS DICCIONARIOS DE LA LISTA TABLA\n",
    "    tf.append(TF(documento)) #SE AGREGA A LA LISTA NUEVOS DICCIONARIOS CREADOS POR LA FUNCI√ìN TF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692d366",
   "metadata": {},
   "source": [
    "## IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39e465e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDF(documentos):                                #RECIBIMOS TODOS LOS DOCUMENTOS\n",
    "    import math                                     #IMPORTAMOS MATH PARA PODER TRABAJAR CON LOG BASE 2\n",
    "    idfDict = {}                                    #CREAMOS UN NUEVO DICCIONARIO PARA IDF\n",
    "    N = len(documentos)                             #CON LEN OBTENEMOS LA CANTIDAD DE DOCUMENTOS Y SE ASIGNA A N\n",
    "    idfDict = dict.fromkeys(documentos[0].keys(), 0)#ASIGNAMOS A LOS CONTENIDOS DE LOS DICCIONARIOS 0\n",
    "    for doc in documentos:                          #VOLVEMOS A OBTENER LA FRENCUENCIA DE LOS TERMINOS PARA ESTE DICCIONARIO\n",
    "        for word, ni in doc.items():\n",
    "            if ni > 0:                              #SOLO AQUELLOS QUE SU VALOR SEA MAYOR A 0 PARA PODER REALIZAR LA DIVISI√ìN\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, ni in idfDict.items():                #RECORREMOS EL DICCIONARIO CREADO ANTERIORMENTE\n",
    "        idfDict[word] = math.log2(N / float(ni))    #ASIGNAMOS LA OPERACI√ìN A LA PALABRA DEL DICCIONARIO IDFDICT \n",
    "    return idfDict    \n",
    "\n",
    "idfs = IDF(tabla) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef5658",
   "metadata": {},
   "source": [
    "## TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89afec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(documentotf, idfs):                 #FUNCION TFIDF RECIBE TANTO LA LISTA TF COMO IDF\n",
    "    tfidf = {}                                #CREAMOS DICCIONARIO TFIDF\n",
    "    for word, valor in documentotf.items():   #CADA PALABRA DEL DOCUMENTO (TF)\n",
    "        tfidf[word] = valor*idfs[word]        #EL VALOR DE LA PALABRA DEL DOCUMENTO SE MULTIPLICA POR EL VALOR DE LA FRECUENCIA INVERSA DE LA PALABRA \n",
    "    return tfidf  \n",
    "tfidf=[]                                  #LISTA TFIDF PARA MOSTRAR NUESTRA TABLA \n",
    "for documentotf in tf:                    #VAMOS RECORRIENDO LA LISTA DE DICCIONARIOS (CADA DICCIONARIO ES UN DOCUMENTO)\n",
    "    tfidf.append(TFIDF(documentotf, idfs))#AGREMOS EL DICCIONARIO RETORNADO A NUESTRA LISTA TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46d5b7",
   "metadata": {},
   "source": [
    "### INDICE INVERTIDO TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99d71af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_invertido_tfidf = {} \n",
    "conjunto = ()\n",
    "i=0\n",
    "for documento in documentos:                   #PARA CADA UNO DE LOS DOCUMENTOS\n",
    "    for termino in terminos:                   #PARA CADA UNO DE LOS TERMINOS\n",
    "        ubi_idf= []                            #LISTA QUE CONTIENE LA UBICACION DEL TERMINO (EL DOCUMENTO) Y SU FRECUENCIA\n",
    "        if termino in documento:               #SI EL TERMINO SE ENCONTRO EN EL DOCUMENTO\n",
    "            if termino not in indice_invertido_tfidf:#SI AUN NO ESTA EL TERMINO EN LA LISTA INVERTIDA\n",
    "                indice_invertido_tfidf[termino] = [] #SE AGREGA AL DICCIONARIO EL TERMINO Y UNA LISTA VACIA DONDE SE ALMACENAR√Å\n",
    "                                               #UBI_FRE\n",
    "            if termino in indice_invertido_tfidf:    #SI EL TERMINO EST√Å EN EL INDICE INVERTIDO\n",
    "                peso=tfidf[i][termino]\n",
    "                ubi_idf.append(i+1)            #SE AGREGA A UBI_FRE EL NUMERO DEL DOCUMENTO \n",
    "                ubi_idf.append(peso)#SE AGREGA A UBI_FRE LA FRECUENCIA DEL TERMINO EN ESE DOCUMENTO\n",
    "                if peso != 0:\n",
    "                    indice_invertido_tfidf[termino].append(ubi_idf)#SE AGREGA AL INDICE INVERTIDO UBI_FRE\n",
    "    i=i+1\n",
    "    if i == len(tabla):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79bfb11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocabulario</th>\n",
       "      <th>Peso TF IDF √≠ndice invertido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v</td>\n",
       "      <td>[[286, 8.451211111832329]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tweeted</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l</td>\n",
       "      <td>[[80, 6.451211111832329], [242, 6.451211111832...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im</td>\n",
       "      <td>[[1, 7.451211111832329], [225, 7.4512111118323...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dia</td>\n",
       "      <td>[[10, 4.750771393691236], [63, 4.7507713936912...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>demasiado</td>\n",
       "      <td>[[349, 8.451211111832329]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>suspender</td>\n",
       "      <td>[[350, 8.451211111832329]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>presente</td>\n",
       "      <td>[[350, 8.451211111832329]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>momentaneamente</td>\n",
       "      <td>[[350, 8.451211111832329]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>lluvia</td>\n",
       "      <td>[[350, 8.451211111832329]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1224 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Vocabulario                        Peso TF IDF √≠ndice invertido\n",
       "0                   v                         [[286, 8.451211111832329]]\n",
       "1             tweeted                                                 []\n",
       "2                   l  [[80, 6.451211111832329], [242, 6.451211111832...\n",
       "3                  im  [[1, 7.451211111832329], [225, 7.4512111118323...\n",
       "4                 dia  [[10, 4.750771393691236], [63, 4.7507713936912...\n",
       "...               ...                                                ...\n",
       "1219        demasiado                         [[349, 8.451211111832329]]\n",
       "1220        suspender                         [[350, 8.451211111832329]]\n",
       "1221         presente                         [[350, 8.451211111832329]]\n",
       "1222  momentaneamente                         [[350, 8.451211111832329]]\n",
       "1223           lluvia                         [[350, 8.451211111832329]]\n",
       "\n",
       "[1224 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd   \n",
    "df = pd.DataFrame([[key, indice_invertido_tfidf[key]] for key in indice_invertido_tfidf.keys()], columns=['Vocabulario ', 'Peso TF IDF √≠ndice invertido'])#SE IMPRIMRE EL DATAFRAME CREADO CON EL NUEVO DICCIONARIO CREADO POR LA FUNCION IDF\n",
    "df.to_excel('TFIDF.xlsx')\n",
    "df   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399aa45f",
   "metadata": {},
   "source": [
    "## CONSULTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77efe61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elimina_tildes(busqueda):\n",
    "    s = ''.join((c for c in unicodedata.normalize('NFD',busqueda) if unicodedata.category(c) != 'Mn'))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d9ab2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_sp_en = set()\n",
    "import io  \n",
    "import unicodedata #PARA LA FUNCION DE ELIMINAR TILDES\n",
    "import spacy #PARA LA FUNCION DE LEMATIZACION\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize  \n",
    "stop_words = set(stopwords.words('Spanish')) \n",
    "#LE QUITAMOS LAS TILDES DEBIDO A QUE AL BUSCAR LE HABREMOS QUITADOS LAS TILDES A NUESTROS DOCUMENTOS\n",
    "for palabra in stop_words:\n",
    "    palabrasinT=elimina_tildes(palabra)\n",
    "    stop_words_sp_en.add(palabrasinT)\n",
    "#MEZCLAMOS LAS STOPWORDS EN INGLES Y ESPA√ëOL\n",
    "stop_words_sp_en.update(set(stopwords.words('English'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc10d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematizacion(busqueda):\n",
    "    sp = spacy.load('es_core_news_sm')#LEMATIZA EN ESPA√ëOL (SE DESCARG√ì LIBRERY)\n",
    "    #sp = spacy.load('en_core_web_sm')\n",
    "    consulta = ''\n",
    "    query=sp(busqueda)\n",
    "    for words in query:\n",
    "        consulta = consulta + words.lemma_ + \" \"\n",
    "    return consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e8a1175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elimina_PV(busqueda):\n",
    "    palabra_sinPV=''\n",
    "    words = busqueda.split() \n",
    "    for word in words:\n",
    "        if not word in stop_words_sp_en:\n",
    "            palabra_sinPV = palabra_sinPV+word+\" \"\n",
    "    return palabra_sinPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "145cc30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesamiento_Consulta(busqueda):\n",
    "    #query= lematizacion(elimina_PV(elimina_tildes(busqueda).lower()))\n",
    "    query= elimina_PV(elimina_tildes(lematizacion(busqueda).lower()))\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb60328",
   "metadata": {},
   "source": [
    "#Frases de prueba\n",
    "\n",
    "juegos del hambre\n",
    "partido aburrido\n",
    "un novio divertido\n",
    "venta de vestidos largos\n",
    "mejores canciones de juan gabriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "208c2e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================\n",
      "Realiza tu consulta Consulta\n",
      "juegos del hambre\n",
      "==============================================================================================\n",
      "Numero de documentos obtenidos para el query y su ocurrencia\n",
      "Mas Relevantes\n",
      "Documento:  28\n",
      "Menos Relevantes\n",
      "Documento:  15\n",
      "Documento:  350\n",
      "Documento:  21\n",
      "Documento:  8\n",
      "==============================================================================================\n",
      "¬øDeseas hacer otra consulta?\n",
      "si\n",
      "==============================================================================================\n",
      "Realiza tu consulta Consulta\n",
      "partido aburrido\n",
      "==============================================================================================\n",
      "Numero de documentos obtenidos para el query y su ocurrencia\n",
      "Mas Relevantes\n",
      "Documento:  341\n",
      "Menos Relevantes\n",
      "Documento:  292\n",
      "Documento:  275\n",
      "Documento:  159\n",
      "==============================================================================================\n",
      "¬øDeseas hacer otra consulta?\n",
      "si\n",
      "==============================================================================================\n",
      "Realiza tu consulta Consulta\n",
      "un novio divertido\n",
      "==============================================================================================\n",
      "Numero de documentos obtenidos para el query y su ocurrencia\n",
      "Mas Relevantes\n",
      "Documento:  50\n",
      "Menos Relevantes\n",
      "Documento:  138\n",
      "Documento:  63\n",
      "Documento:  187\n",
      "Documento:  43\n",
      "==============================================================================================\n",
      "¬øDeseas hacer otra consulta?\n",
      "si\n",
      "==============================================================================================\n",
      "Realiza tu consulta Consulta\n",
      "venta de vestidos largos\n",
      "==============================================================================================\n",
      "Numero de documentos obtenidos para el query y su ocurrencia\n",
      "Mas Relevantes\n",
      "Documento:  188\n",
      "Menos Relevantes\n",
      "==============================================================================================\n",
      "¬øDeseas hacer otra consulta?\n",
      "si\n",
      "==============================================================================================\n",
      "Realiza tu consulta Consulta\n",
      "mejores canciones de juan gabriel\n",
      "==============================================================================================\n",
      "Numero de documentos obtenidos para el query y su ocurrencia\n",
      "Mas Relevantes\n",
      "Documento:  198\n",
      "Menos Relevantes\n",
      "Documento:  122\n",
      "Documento:  231\n",
      "Documento:  338\n",
      "Documento:  261\n",
      "Documento:  252\n",
      "Documento:  191\n",
      "Documento:  175\n",
      "Documento:  173\n",
      "Documento:  172\n",
      "Documento:  162\n",
      "Documento:  134\n",
      "Documento:  72\n",
      "Documento:  71\n",
      "Documento:  50\n",
      "Documento:  33\n",
      "Documento:  5\n",
      "==============================================================================================\n",
      "¬øDeseas hacer otra consulta?\n",
      "no\n",
      "==============================================================================================\n",
      "Gracias por tu consulta\n",
      "==============================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while(True):\n",
    "    Query=''\n",
    "    print(\"==============================================================================================\")\n",
    "    print(\"Realiza tu consulta Consulta\")\n",
    "    lectura = input()\n",
    "    Query = preprocesamiento_Consulta(lectura)\n",
    "    aparicion(Query.rstrip())\n",
    "    print(\"==============================================================================================\")\n",
    "    print(\"¬øDeseas hacer otra consulta?\")\n",
    "    respuesta = input()\n",
    "    if respuesta == 'no':\n",
    "        print(\"==============================================================================================\")\n",
    "        print(\"Gracias por tu consulta\")\n",
    "        print(\"==============================================================================================\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57db7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import operator\n",
    "def aparicion(query):\n",
    "    documentos_Presentes= []\n",
    "    dict_aparicion ={}\n",
    "    print(\"==============================================================================================\")\n",
    "    palabras = query.split(\" \")\n",
    "    #IMPRIME LOS DOCUMENTOS EN LOS QUE APARECE LAS PALABRAS JUNTO CON SU PESO\n",
    "    #print(\"Palabra y sus pesos\")\n",
    "    for palabra in palabras:\n",
    "        if palabra in indice_invertido_tfidf:\n",
    "            contenido = indice_invertido_tfidf[palabra]\n",
    "            for cont in contenido:\n",
    "                documentos_Presentes.append(cont[0])                #SE TOMA EL [0] DEBIDO A QUE ESTE ES EL DOCUMENTO\n",
    "            if len(contenido) == 0:                                 #SI LA LISTA ESTA VACIA SIGNIFICA QUE APARECEN EN TODOS LOS DOCUMENTOS\n",
    "                print(\"=>\",palabra,\" esta en todos los documentos\")\n",
    "            else:\n",
    "                '''print(\"=>\",palabra,\": \")\n",
    "                pprint.pprint(contenido)'''\n",
    "    #PARA OBTENER OCURRENCIA DE DOCUMENTOS (NO SE HACE USO DE LOS PESOS)\n",
    "    for doc in documentos_Presentes:\n",
    "        if doc in dict_aparicion:\n",
    "            dict_aparicion[doc]+=1\n",
    "        else:\n",
    "            dict_aparicion[doc]=1\n",
    "    #print(dict_aparicion)\n",
    "    #IMPRIMIR DOCUMENTOS ORDENADOS POR EL MAYOR RELEVANTE\n",
    "    print(\"Numero de documentos obtenidos para el query y su ocurrencia\")\n",
    "    ordenados = list(reversed(sorted(dict_aparicion.items(), key=operator.itemgetter(1))))\n",
    "    for i in range(len(ordenados)):\n",
    "        if i == 0:\n",
    "            print(\"Mas Relevantes\")\n",
    "            print(\"Documento: \",ordenados[i][0])\n",
    "            print(\"Menos Relevantes\")\n",
    "        else:\n",
    "            print(\"Documento: \",ordenados[i][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
